 一般而言,人们评估一个Web站点的性能如何,通常先置身于用户的角度,访问该站点的一系列页面,体验等待时间.  
 当用户输入页面地址后,浏览器获得了用户希望访问该地址的意图,便**向站点服务器发起一系列的请求**.  
 这些请求不光包括对页面的请求,还还包括对页面中许许多多组件的请求,比如图片,层叠样式表(css),脚本(javascript),内嵌页面(iframe)等.接下来的一段事件,浏览器等待服务器的响应以及返回的数据.
 待浏览器获得所有的返回数据后,经过**本地的计算和渲染**,最终一副完整的页面才呈现于用户眼前.
### 1.1 等待的真相  
 等待的时间里经历了:  
 1. 数据在网络上传输的时间.包括浏览器端主机发出的请求数据经过网络到达服务器的时间,以及服务器的回应数据经过网络回到浏览器端主机的时间.这两部分时间都可以视为某一大小的数据从某主机开始
 发送一直到另一端主机全部接受所消耗的总时间,我们称它为**响应时间**,它的决定因素主要包括发送的数据量和网络带宽.  
 2. 站点服务器处理请求并生成回应数据的时间.主要消耗在服务器端,包括非常多的环节,我们一般用另一个指标来衡量这部分时间,即每秒处理请求数,也称**吞吐率**,注意这里的吞吐率不是指单位时间处理的数据量,而是请求数.影响服务器吞吐率的因素非常多,比如服务器的
 并发策略,I/O模型,I/O性能，CPU核数等,当然也包括应用程序本身的逻辑复杂度等.  
 3. 浏览器本地计算和渲染的时间.消耗在浏览器端,它依赖的因素包括浏览器采用的并发策略,样式渲染方式,脚本解释器的性能,页面大小,页面组件数量,页面组件缓存状况,页面组件域名分布以及域名DNS解析等,并且其中一些因素随着各厂商浏览器版本的不同而略有变化.  
 可见一个页面包含了若干个请求,每个请求都或多或少地涉及以上这些过程,加入有一个关键环节稍加拖延,整体的速度便可想而知.  

### 1.2 瓶颈在哪里  
 **系统性能的瓶颈**:是指影响性能的关键因素,这些因素随着系统的运行又会发送不断地变化或迁移,比如由于站点用户组成结构的多样性和习惯的差异,导致在不同时段系统的瓶颈各不相同,又如站点在数据存储量或浏览器增长到不同级别时,系统瓶颈也会发生迁移.一旦找到真正影响系统性能的主要因素,也就是性能瓶颈,就要坚决对其进行调整和优化.  
 同时,在这些关键因素的背后,也存在很多不能忽略的子因素,构成了性能优化的"长尾效应",也就是说如果你对某个子因素背后的问题进行优化,可能会带来性能上的少许提升,也许不被察觉,但是多个自因素的优化结果也许会叠加在一起,
 带来性能上可观的提升.对于诸多子因素的优化,需要稍加谨慎,花点时间考虑这种优化是否值得,以及是否会带来潜在的副作用,还有其他依赖的非技术因素.  
 然而,不论是关键因素还是子因素,它们的背后都是影响系统性能的问题所在,问题本身并不涉及关键性,只有在不同的系统和应用场景下,才会显示出其是否关键.  

### 1.3 增加带宽  
 我们通过介绍数据的网络传输原理,彻底揭开带宽的本质,以及数据传输响应时间的依赖因素和计算方法.  

### 1.4 减少网页中的HTTP请求  
 web站点中几乎任何一个网页都包含了多个组件,每个组件都需要下载,计算或渲染,这些行为都会消耗时间,减少这些行为便可加快网页的展示速度,但往往我们需要在优雅的网页表现和性能之间权衡取舍,找到最优的均衡点至关重要.一些尝试:  
+ 设计更加简单的网页,使其包含较少的图片和脚本,但是这可能牺牲了美观和用户交互.  
+ 将多个图片合并为一个文件,利用CSS背景图片的偏移技术呈现在网页中,避免了多个图片的下载.  
+ 合并JavaScript脚本或者CSS样式表.  
+ 充分利用HTTP中的浏览器端Cache策略,减少重复下载.  
 这些技巧来自于Web网页前端的优化,本书偏重于站点服务器端的性能改善和规模扩展.  

### 1.5 加快服务器脚本计算速度  
 大多数涉及性能问题的站点都会使用各种各样的服务器端脚本语言,比如:PHP,Ruby,Python,ASP.NET,JSP等,这些脚本语言用来编写动态内容或者后台运行的小程序,已经成了几乎所有站点的首选.用这些脚本语言编写的程序文件需要通过相应的脚本解释器进行解释后生产中间代码,然后依托在解释器的运行环境中运行.所以**生成中间代码**这部分时间又成为大家获取性能提升而瞄准的一个目标.
 对于一些拥有较强商业支持的脚本语言,比如ASP.NET和JSP,均有内置的优化方案,比如解释器对某个脚本程序第一次解释的时候,将中间代码缓存起来,以供下次直接使用.对于开源类的脚本语言,也有很多第三方组件来提供此类功能,比如PHP的ACP组件等.  

### 1.6 使用动态内容缓存  
 在实际应用中,动态内容缓存可能是大家用的最多的技术,但是不见得所有的动态内容都适合使用网页缓存,缓存带来的性能提升恰恰与有些动态数据实时交互的需求形成矛盾,而解决该问题的唯一途径不是技术本身,而是你如何权衡.  
 **动态内容缓存**是将数据和表现整体打包,而某些动态内容的计算时间其实主要消耗在一些烦人的特殊数据上,这些数据频繁更新或读取,这时,我们为了提高缓存的灵活性和命中率,以及性能的要求,便开始考虑数据缓存.  
 
### 1.7 使用数据缓存  
 更加细粒度的**数据缓存**避免了过期时大量相关网页的整体更新.  
 数据缓存存储在哪里 这个问题需要考虑多方面因素.  
 1. 速度.如果无法提供高效的读写访问,那么这部分数据缓存很可能不久便成为新的系统瓶颈.  
 2. 数据缓存的共享至关重要.如:同一主机上不同进程间的共享,网络上不同主机间的共享.  
 
### 1.8 将动态内容静态化  
 在动态内容缓存技术的实现机制中,虽然避免了可观的重复计算,但是每次还都需要调用动态脚本解释器来判断缓存是否过期以及读取参数,这似乎有些多余,
 而且关键是消耗了不少时间.直接让浏览器访问这些动态内容的缓存不是更好么?在这种情况下缓存成为直接暴露给前端的HTML网页,而整个缓存控制机制也发生了根本的变化,我们普遍称它为静态化.静态网页独立于脚本解释器而存在.  
 
### 1.9 更换Web服务器软件  
 我们要停止只通过压力测试盲目地选择web服务器软件,我们需要学习一些稍显底层的知识来武装自己.我们将介绍Web服务器在并发策略方面的各种设计和其动机及本质.  
 
### 1.10 页面组件分离  
 好处:可以根据不同组件的需求,比如下载量,文件大小,对服务器各种资源的需求等,有针对性的采用不同的并发策略,并且提供最佳的物理资源.  
 
### 1.11 合理部署服务器  
 部署web站点各类服务器的时候,是否能够找到合理的位置部署服务器至关重要.  
 我们当然希望Web站点的用户和服务器位于同一个互联网运营商的网络内.  
 我们知道,在基于IP寻址的互联网中,IP地址相近的主机之间通信,数据经过少数的路由器即可到达,比如同一局域网内通信或者接入同一城市交换节点的局域网之间通信,这种情况下数据到达时间相对较短.  
 如果通信的两端主机位于不呕吐功能运行商的互联网中,那么数据必须应该两个互联网运营商的顶级交换节点和骨干线路,在这个过程中数据要经过更多次的存储转发,而且各互联网顶级交换节点之间又存在出口带宽的限制,如果互联网之间数据通信量比较大的话,那么这个顶级交换节点,也就是"出口",将会是瓶颈所在.  
 
### 1.12 使用负载均衡  
 到此为止,我们已经最大程度地发挥了单台Web服务器的处理能力,但是,当它所承受的压力到达极限时,就需要有更多的服务器来分担工作,我们需想办法将流量合理转移到更多的服务器上.为此,我们需通过各种不同的方法来实现Web负载均衡,可能是简单的HTTP重定向,或者是基于DNS的轮询解析,或者通过反向代理服务器来实现负载均衡调度,还可以通过LVS来组建服务器集群.  
 
### 1.13 优化数据库  
 频繁的数据库连接和释放将导致数据访问等待时间的加长,这段时间浪费得毫无意义.  
 1. 使用**数据库持久连接**有效地解决了这一难题.它包括不呕吐功能程度上的持久化,本质的区别在于持久连接的应用范围和生命周期,比如某个**进程内部的全局数据库连接**,供进程内所有计算任务共享,在这个进程终止后便被释放;或者在某个动态内容的执行周期内,**代码层面的持久连接对象**,在动态内容计算结束后便不复存在;还有**跨进程的数据库连接池**,保存多个持久连接供应用程序重复使用.在这些采用数据库持久连接的应用设计中,同时还要注意数据访问的线程安全性.  
 2. 在设计数据库的表结构时,索引的合理使用对于依赖数据库访问的Web应用至关重要.  
 3. 数据库存储引擎.合理为你的Web站点选择数据库存储引擎.  
 4. 当单台数据库服务器无法满足应付整个站点的需要.我们将数据库散列在多台主机,包括必要的冗余数据,以此来合理地分散数据库的密集访问,数据库扩展便成为我们考虑的方案.  
 
### 1.14 考虑可扩展性  
 可扩展性并不是性能和速度的概念,它是指系统负载增大时,通过增加资源来提高性能的能力.高性能往往需要通过这种能力来实现快速扩展.另一方面,可扩展性的目的在于适应负载的变化,从扩展的技术上来看,又包含了很多对局部性能的思考,以及了解何时需要扩展,这离不开对站点性能的把握.  

### 1.15 减少视觉等待  
 涉及人机交互的相关知识
