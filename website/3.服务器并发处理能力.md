 我们希望一台服务器在单位时间内能处理的请求越多越好,这也成了Web服务器的能力高低所在,它体现了我们常说的"服务器并发处理能力".本章所说的服务器,主要指用于提供HTTP服务的服务器,但是本章中所涉及的一些关于操作系统和内核的内容,并不限于Web服务器.  
## 3.1 吞吐率  
 我们用**吞吐率**来描述Web服务器的并发处理能力,即单位时间内Web服务器处理的请求数.  
 在一些常见的Web服务器软件中,通常会提供当前服务器运行状况以及吞吐率的查看方法,帮助我们对服务器吞吐率随时进行了解和监控,比如Apache的mod_status模块和Lighttpd的mod_status模块.  
#### 吞吐率和压力测试  
 相对于吞吐率,我们更加关心的是**最大吞吐率**,即单位时间内服务器能够处理的最大请求数.我们普遍采用"压力测试"的方法,通过模拟足够数目的并发用户数,分别持续发送一定的HTTP请求,并统计测试持续的总时间,计算出基于这种"压力"下的吞吐率,即为一个平均计算值.  
 
 另一方面,在Web服务器的实际工作中,其处理的HTTP请求通常包括对很多不同资源的请求,也就是请求不同的URL,比如这些请求有的是获取图片,有的是获取动态内容,显然服务器处理这些请求所花费的时间各不相同,而这些请求的不同时间的组成比例又是不确定的.但是我们在压力测试的时候若想要模拟这种不同请求交错地情况会给我们考察处理器并发能力带来难以想象的困难,我们知道在一个含有较多变量的数据模型中求解最优解是非常困难的,所以
 我们一般都简化模型,对同一个特定的有代表性的请求进行压力测试,然后根据需要,对多个请求的吞吐率按照比例计算加权平均值.  
 
 正是因为这些请求性质的不同,Web服务器并发能力强弱的关键便在于如何针对不同的请求性质来设计**最优并发策略**.  
#### 压力测试的前提条件  
 吞吐率的前提条件包括压力的描述和请求性质的描述,压力的描述包括**并发用户数**和**总请求数**,也就是模拟多少个用户同时向服务器发送多少个请求.请求性质则是对请求的URL所代表的**资源的描述**.  
#### 并发用户数  
 指:在某一时刻同时向服务器发送请求的用户总数.  
 对于压力测试中提到的每一个用户,连续发送请求实际上是指在发送一个请求并接收到响应数据后再发送下一个请求.故从微观层面上来看,
 当一个用户向服务器连续进行1000次请求的过程中,任何时刻服务器的网卡接收缓冲区中只有来自该用户的一个请求,而100个用户同时向服务器分别进行10次请求的过程中,
 服务器网卡接收缓冲区中最多有100个等待处理的请求,显然这时候服务器的压力更大.  
 
 **并发用户数**别名:**并发数**,**并发连接数**.  
 **服务器的最大并发数**,需要在服务器和用户双方期待的最大利益下进行权衡.  
 
 当**实际并发用户数**大于我们通过压力测试得出的服务器所能支持的最大并发数时,必然造成一部分用户需要等待超过预期的时间,影响了站点的服务质量.所以,得出最大并发数的意义,在于了解服务的承载能力,并且结合用户规模考虑适当的扩展方案.  
 在考虑实际用户规模的时候,我们要了解,用户访问Web站点通常使用的浏览器在下载一个网页以及网页中多个组件时,采用多线程的并发下载方式,但是对同一域名下URL的并发下载数是有最大限制的.虽然如此,一个真实的用户可能会给服务器带来两个或更多的并发用户数的压力.在书中为简化模型认为每个用户的并发下载数为1.  
 从Web服务器的角度来看,实际并发用户数也可以理解为Web服务器当前维护的代表不同用户的文件描述符总数,也就是**并发连接数**.  
 
 当实际并发用户数稍稍大于服务器所能维护的文件描述符上限时.如果请求的性质决定了处理每个请求花费的时间非常少,我们希望服务的最大并发数可以大于最大并发连接数.如果请求的性质决定了处理每个请求要花费相当长的时间,我们希望服务的最大并发用户数小于理论上的最大并发连接数.  
 
 **总结**:从某种意义上来说,Web服务器所做的工作的本质就是,争取以最快的速度将内核缓冲区中的用户请求数据一个不剩地都拿回来,然后进最大努力同时快速处理完这些请求,并将响应数据放到啮合维护的另一块用于发送数据的缓冲区中,接下来再尽快处理下一拨请求,并尽量让用户请求在内核缓冲区中不要等太久.  
#### 请求等待时间  
 **用户平均请求等待时间**主要用于衡量服务器在一定并发用户数的情况下,对于单个用户的服务质量;而**服务器平均请求处理时间**用于衡量服务器的整体服务质量,它其实就是吞吐率的倒数.  
#### 硬件环境  
 在以上压力测试中,我们普遍使用的Web服务器基本硬件配置如下:  
 CPU:Intel(R) Xeon(R) CPU 1.60GHz  
 内存:4GB  
 硬盘转速:15k/min  
#### 压力测试  
 有了这些前提,我们就可以用压力测试软件来计算吞吐率了,本书中大部分压力测试使用Apache附带的ab,它非常容易使用,完全可以模拟以上各种前提条件.另外,ab可以直接在Web服务器本地发起测试请求,这至关重要,因为我们希望测试的是服务器的处理时间,而不包括数据的网络传输时间以及用户PC本地的计算时间.  
 ab进行一切测试的本质都是基于HTTP,所以可以说它是对于Web服务器软件的黑盒性能测试,它获得的一切数据和计算结果,都可以通过HTTP来解释.  
 
 另有一些压力测试软件,包括LoadRunner,Jmeter等,则是不同程度上包含了服务器处理之外的时间,比如LoadRunner运行在用户PC上,可以录制浏览器的行为,这种测试的结果往往侧重于站在用户的角度.  
 
 我们对Web服务器的几个常见性能指标做了详细介绍,影响这些指标的因素,除去服务器的硬件配置,就是前面提到的**并发策略**.简单地说,并发策略的设计就是在服务器同时处理较多请求的时候,如何合理协调并充分利用CPU计算和I/O操作,使其在较大并发用户数的情况下提供较高的吞吐率.  
 并不存在一个对所有性质的请求都高效的并发策略,我们只能也只有了解并根据这些性质来选择最佳的并发策略,高性能Web站点才会离你更近一步.  
 
## 3.2 CPU并发计算  
 服务器之所以可以同时处理多个请求,在于操作系统通过**多执行流体系设计**使得多个任务可以轮流使用系统资源,这些资源包括**CPU,内存以及I/O**等.  
#### 进程  
 多执行流的一班实现便是进程.从本质上讲,多进程的好处并不仅仅在于CPU时间的轮流使用,还在于对CPU计算和I/O操作进行了很好的重叠作用,这里的I/O主要是指磁盘I/O和网络I/O,它们的速度比CPU慢得多.事实上,大多数进程的时间都主要消耗在了I/O操作上.  
 进程的调度由内核来进行,从内核的观点看,进程的目的就是担当分配系统资源的实体.同时,进程也可以理解为记录程序实例当前运行到什么程度地一组数据,多个进程通过不同的进程描述符与这些数据进行关联.  
 每个进程都有自己独立的内存地址空间和生命周期.当子进程被父进程创建后,便将父进程地址空间的所有数据复制到自己的地址空间,完全继承父进程的所有上下文信息,它们之间可以通信,但是不互相依赖,也无权干涉彼此的地址空间.  
 进程的创建使用fork()系统调用,它的开销虽然不是很昂贵,但是在繁忙的服务器上频繁地创建进程,其开销可能成为影响性能的主要因素.  
#### 轻量级进程  
 轻量级进程由一个新的系统调用clone()来创建,并由内核直接管理, 像普通进程一样独立存在,各自拥有进程的描述,但是这些进程已经允许共享一些资源,比如地址空间,打开的文件等.轻量级进程减少了内存的开销,并为多进程应用程序的数据共享提供了直接支持,但是其上下文切换的开销还是在所难免的.  
#### 线程  
 POSIX线程的两种实现方式:  

1. 定义了线程的接口"phread",有很多种具体实现,有些不是由内核来直接支持,在这种情况下,从内核的角度看,多线程知识一个普通的进程,它是由用户态通过一些库函数模拟实现的多执行流,所以多线程的管理完全在**用户态**完成,这种实现方式下线程切换的开销相比于进程和轻量级进程都要少些,但是她在处理器的服务器(SMP)中表现较差,因为**只有内核的进程调度器才有权利分配多个CPU的时间**.  
2. LinuxThreads,它可以说是内核级的线程库,因为它通过clone()来创建线程,也就是说它的实现原理是将线程和轻量级进程一对一关联,每个线程实际上就是一个轻量级进程,这使得线程完全由内核的进程调度器来管理,所以他对于SMP的支持良好,但线程切换的开销相比于用户态线程要多一些.  

#### 进程调度器  
 内核中的进程调度器维护着各种状态(挂起,就绪或其他等)的进程队列.进程调度器的一项重要工作就是决定下一个运行的进程,如果运行队列中不止有一个进程,每个进程要高速进程调度器它们的紧急程度,即进程优先级.进程优先级除了可以由进程自己决定,进程调度器在进程运行时也可以动态调整它们的优先级,目的是为了让所有进程更好地重叠利用系统资源.  
#### 系统负载  
 在进程调度器维护的运行队列中,任何时刻至少存在一个进程,那就是正在运行的进程.而当运行队列中不止有一个进程时,就说明此时CPU比较抢手,其他进程还在等着呢,进程调度器应该尽快让正在运行的进程释放CPU.  
 **系统负载越高,代表CPU越繁忙,越无法很好地满足所有进程的需要**  
 定义:系统负载是指单位时间内运行队列中就绪等待的进程数平均值.所以当运行队列中就绪进程不需要等待就可以马上获得CPU时,系统负载非常低,系统.  响应非常快.  
#### 进程切换  
 为了让所有的进程可以轮流使用系统资源,进程调度器在必要的时候挂起正在运行的进程,同时恢复以前挂起的某个进程,这种行为称为**进程切换**,也就是**上下文切换**,上下文表示进程运行到何种程度.  
 进程拥有自己独立的内存空间,但是每个进程都只能共享CPU寄存器.一个进程被挂起的本质就是将它在CPU寄存器中的数据拿出来暂存在内核态堆栈中,而一个进程恢复工作的本质就是将它的数据重新装入CPU寄存器,这段装入和移出的数据我们称为"硬件上下文",它也是进程上下文的一部分,初次之外,进程上下文中还包含了进程运行时需要的一切状态信息.  
 
 如果我们希望服务器支持较大的并发数,那么就要尽量减少上下文切换次数,最简单的做法就是减少进程数,尽量使用线程配合其他I/O模型来设计并发策略.  
#### IOWait  
 在CPU的使用率报告中,除了用户控件和内核空间的CPU使用率以外,通常我们HIA关注IOWait,它是指CPU空闲并且等待I/O操作完成的时间比例.它的设计触发点是用来衡量CPU的性能.当IOWait很高的时候,说明当前任务的CPU时间开销相对于I/O操作时间来说比较少,通常对于依赖磁盘I/O的应用来说,这比较正常,因为CPU的速度比磁盘I/O越来越快,特别是在随机的磁盘I/O操作中,大量的寻址时间是无法避免的.  
 IOWait有时也有可能会误导我们,我们需要判断到底是实际的磁盘I/O提高了还是其实只是CPU使用率提高了.总之它是一个耐人寻味的指标,你需要根据站点的实际情况来做出合理的判断.  
#### 锁竞争  
 在服务器处理大量并发请求的时候,多个请求处理任务之间存在一些资源抢占竞争.这就需要有一种机制来维持秩序,比如多个线程同时写一个日志文件,为了防止写入的数据发生位置错乱,就需要我们自己来控制先后顺序,也就是要保证线程安全.我们一般用**锁**机制来控制资源的占有,当一个任务占有资源的时候,我们锁住资源,这时候其他任务都在等待锁的释放,这种现象我们称为锁竞争.  
## 3.3 系统调用  
 前面的内容中提到进程的**用户态**和**内核态**两种运行模式,这是Linux为进程设计的两种运行级别,进程可以在两种模式之间切换,这也需要一定的开销.进程通常运行在用户态,这时候可以使用CPU和内存来完成一些任务(如进程数学计算),而当进程需要对硬件外设进行操作的时候(如读取磁盘文件,发送网络数据等),就必须切换到内核态,这时候它将拥有更多的权利来操控整个计算机,当在内核态的任务完成后,进程又切换回用户态.  
 进程切换到内核态的一系列过程,对使用高级语言的开发者来说是透明的,程序代码只在需要的时候进行系统调用即可.内核提供了一系列的系统调用,同时,C库函数将系统调用封装在编程接口,提供给用户态的进程.用户态的进程可以直接进行系统调用,也可以使用封装了系统调用的C API,比如write()系统调用,它的封装API之一就是用于发送网络数据的send().  
 
 这种**用户态和内核态的分离**,动机主要在于提高系统底层安全性以及简化开发模型.由于所有进程都必须通过内核提供的系统调用来操作硬件,所以不必担心应用程序对硬件进行非法操作,由于将底层的实现都屏蔽在了系统调用中,也大大简化了用户态应用开发的难度.由于系统调用设计进程胸用户态到内核态的切换,导致一定的内存空间交换,这也是一定程度上的上下文切换,所以系统调用的开销通常认为是比较昂贵的.**减少不必要的系统调用**,这也是Web服务器性能优化的一个方面.  
 系统调用的减少对于降低请求处理时间(吞吐率增加)有着不可忽略的作用.  
## 3.4 内存分配  
 在Web服务器的工作过程中,需要用到大量的内存,这使得内存的分配和释放工作显得尤为重要.Web服务器处理成千上万的HTTP请求,内存堆栈的分配和复制次数变得更加频繁.我们可以通过改善数据结构和算法复杂度来适当减少数据复制时间,而对于内存的分配,很多Web服务器使用了各自的策略来提高效率.  
 **Apache(多进程模型)**在运行时的内存使用量很大.它使用了基于内存池策略的内存管理方案,并将它抽象出来后移入ARP库中作为通用内存管理模块.这种方案使得Apache在运行开始时便一次性申请大片的内存作为内存池,这样在随后需要的时候只要在内存池中直接获取,而不需要再次分配,我们知道频繁的内存分配和释放会引发一定时间的内存整理,这本身便影响了性能.另一方面,内存池的使用使得Apache的内存管理更加安全,因为即便是某处内存使用后忘记释放也没关系,内存池在Apache关闭时会彻底释放.即便使用了内存池,由于机制问题,Apache仍然就像拖着沉重身体的傻大个,内存池对于性能的弥补微不足道.  
 **Lighttpd(单进程模型)**内存使用量小很多.  
 **Nginx(单进程模型)**内存使用量更小.  
 
 内存分配策略的设计是Web服务器并发处理能力的重要保障.  
## 3.5 持久连接  
 **持久连接**(长连接),它本身是TCP通信的一种普通方式,即在一次TCP连接中持续发送多份数据而不断开连接;  
 与之相反的是**短连接**,也就是建立连接后发送一份数据便断开,然后再次建立连接发送下一份数据.  
一般而言,是否采用持久连接完全取决于应用的特点和需要.从性能的角度看,建立TCP连接的操作本身便是一项不小的开销,所以在允许的情况下,连接次数越少,越有利于性能的提升.  

 在Web应用**通信层**中,由于HTTP的无状态特性,使得HTTP通信毫不依赖于TCP长连接,长久以来大家习惯了"一次性"的HTTP通信,即一次TCP连接处理一个HTTP请求.然而回归**传输层**,长连接的好处显而易见,它对于密集型的图片或网页等小数据的请求处理有着明显的加速作用.  
 
 HTTP长连接的实施需要浏览器和Web服务器的共同协作,缺一不可.一方面,浏览器需要保持一个TCP连接并重复利用,不断地发送多个请求,另一方面,服务器不能过早地主动关闭连接.要实现这一点并不难,目前的浏览器普遍支持长连接,表现在其发出的HTTP请求数据头中包含关于长连接的声明:Connection:Keep-Alive  这种声明的含义在于高速服务器"如果可以的话,请让我重复这个连接"也就是告诉服务器不要在处理完当前请求后就马上关闭连接.同时,在Web服务器上也要打开长连接的支持,幸运的是,目前所有主流的Web服务器软件都支持长连接,比如在Apache2.2.11中,长连接的支持默认为开启状态,当然你也可以通过以下方式关闭:KeepAlive Off   
 对于长连接的使用关键在于什么时候关闭它.长连接的设置同时出现在浏览器和Web服务器上,因为双发都可以主动关闭.对于IE7,默认的超时时间为1分钟,你也可以通过修改注册表来修改超时时间.对于Web服务器,一般会提供超时时间的配置参数,比如在Apache中,可以通过httpd.conf中的如下参数进行配置:KeepAliveTimeout 30 以上命令设置超时时间为30秒,而在默认情况下,Apache将其设置为5秒.值得注意的是,浏览器和Web服务器各自的超时时间设置不一定一致,所以在实际运行中,是以最短的超时时间为准.  
 
 经过测试,我们得出一些结论:合理地使用长连接会使得吞吐率增高;系统调用数减少(如socket的accept()和close()).  
 有时长连接超时时间过长,对Web服务器的性能也会产生不利的影响.  
 对于Apache这样的多进程模型来讲,如果长连接超时时间过长,比如60秒,那么即便是浏览器没有任何请求,而Apache仍然维持着连接该浏览器的子进程,一旦并发用户数较多,那么Apache将维持着大量的空闲进程,严重影响了服务器性能.  
 对于使用多线程的轻量级Web服务器(如:Nginx),长连接的超时时间过长,导致资源无法占有而引发的损失已经超过了由于重复连接所造成的损失,这的确得不偿失.  
 **持久连接的动机**:尽量减少连接次数,尽量重用连接通道.  
## 3.6 I/O模型  
 数据生命的意义在于输入/输出,计算机的重要工作之一便是负责各种设备的数据输入/输出,也就是I/O操作.  
 I/O操作根据设备的不同分为很多种类型,比如**内存I/O(快),网络I/O(慢),磁盘I/O**(慢).  
 本章我们主要关注**网络数据的接收和发送**,**磁盘的访问**.我们将其归纳为多种模型,称为I/O模型,它们的本质区别便在于CPU的参与方式.  
#### PIO与DMA  
 说说慢速I/O设备和内存之间的数据传输方式.  
 
 1. 很早以前的**PIO**:磁盘和内存之间的数据传输需要CPU控制,即我们读取磁盘文件到内存中,数据要经过CPU存储转发.显然这种方式非常不合理,需要占用大量的CPU时间来读取文件,造成文件访问时系统几乎停止响应.  
 2. **DMA(直接内存访问)**取代了PIO:不经过CPU而直接进行磁盘和内存的数据交换.在DMA模式下,CPU值需要向DMA控制器下达指令,让DMA控制器来处理数据的传送即可,DMA控制器通过系统总线来传输数据,传送完毕再通知CPU,这样就在很大程度上降低了CPU占有率,大大节省了系统资源,而它的传输速度与PIO的差异其实并不是十分明显,因为这主要取决于慢速设备的速度.  
 
#### 同步阻塞I/O  
 当进程调用某些涉及I/O操作的系统盗用后库函数时,比如:accept(),send(),recv()等,进程便暂停下来,等待I/O操作完成后再继续进行.这是一种简单而有效地I/O模型,它可以和多进程合起来有效地利用CPU资源,但是其代价就是多进程的大量内存开销.  
#### 同步非阻塞I/O  
 在同步阻塞I/O中,进程实际上等待时间可能包括两部分,一个是等**待数据的就绪**,另一个是**等待数据的复制**,对于网络来说,前者时间可能更长一点.与此不同的是,同步非阻塞I/O的调用不会等待数据的就绪,如果数据不可读或者不可写,它会立即告诉进程.比如我们使用非阻塞recv()接收网络数据的时候,如果网卡缓冲区中没有课接收的数据,函数就及时返回,告诉没有进程数据可读了.相比于阻塞I/O,这种非阻塞I/O结合反复轮询来尝试数据是否就绪,防止进程被阻塞,最大的好处便在于可以在一个进程里同时处理多个I/O操作.但正是由于需要进程执行多次的轮询来查看数据是否就绪,这花费了大量的CPU时间,使得进程处于忙碌等待状态.  
 
 **非阻塞I/O一般只针对网络I/O有效**,我们只要在socket的选项设置中使用O_NONBLOCK即可,这样对于该socket的send()或revc()便采用非阻塞方式.值得注意的是,对于磁盘I/O,非阻塞I/O并不产生效果.  
#### 多路I/O就绪通知    
 在实际应用中,特别是Web服务器,同时处理大量的文件描述符是比不可少的,但是使用同步非阻塞I/O显然不是最佳的选择,在这种模型下,我们知道如果服务器想要同时接受多个TCP连接的数据,就必须轮流对每个socket调用接收数据的方法,比如revc().不管这些socket有没有可以接收的数据,都要询问一遍,假如大部分socket并没有数据可以接收,那么进程便会浪费很多CPU时间用于检查这些socket,这显然不是我们所希望看到的.  
  
  多路I/O就绪通知的出现,提供了对大量文件描述符就绪检查的高性能方案,它允许进程通过一种方法来同时监视所有文件描述符,并可以快速获得**所有就绪的文件描述符**,然后只针对这些文件描述符进行数据访问.   
  
  需要注意的是,I/O就绪通知只是帮助我们快速获得就绪的文件描述符,当得知数据就绪后,就访问数据本身而言,仍然需要选择阻塞或非阻塞的方式,一般我们选择非阻塞方式,以防止任何意外的等待阻塞整个进程,比如有时就绪通知只代表一个内核的提示,也许此时文件描述符尚未真正准备好或者已经被客户端关闭连接.  

在安装一些Web服务器软件的时候,configure过程中会检查当前系统支持的多路I/O就绪通知方法.  

#### 内存映射  
 Linux内核提供一种访问磁盘文件的特殊方式,它可以将内存中某块地址空间和我们要指定的磁盘文件相关联,从而把我们对这块内存的访问转换为对磁盘文件的访问,这种技术成为**内存映射**.  
 在大多数情况下,使用内存映射可以提高磁盘I/O的性能,它无需使用read()或write()等系统调用来访问文件,而是通过mmap()系统调用来建立内UC你和磁盘文件的关联,然后像访问内存一样自由地访问文件.  

有两种类型的内存映射:  
1. 共享性.它可以将任何对内存的**写操作**都同步到磁盘文件,而且所有映射同一个文件的进程都共享一个进程对映射内存的修改;  
2. 私有型.它映射的文件只能是**只读文件**,所以不可以将对内存的写同步到文件,而且多个进程不共享修改.  

显然,共享型内存映射的效率偏低,因为如果一个文件被很多进程映射,那么每次修改同步将花费一定的开销.  
#### 直接I/O  
 在Linux2.6中,内存映射和直接访问文件没有本质上差别,因为数据从进程用户态内存空间到磁盘都要经过两次复制,即在磁盘与内核缓冲区之间以及在内核缓冲区与用户态内存空间.  
 
 引入内核缓冲区的目的在于提高磁盘文件的访问性能,因为当进程需要读取磁盘文件时,如果文件内容已经在内核缓冲区中,那么久不需要再次访问磁盘;而当进程需要向文件中写入数据时,实际上只是写到了内核缓冲区便告诉进程已经写成功,而真正写入磁盘是通过一定的策略进行延迟的.  
 
 然而,对于一些较复杂的应用,比如数据库服务器,它们为了充分提高性能,希望绕过内核缓冲区,由自己在用户态空间实现并管理I/O缓冲区,包括缓存机制和写延迟机制等,以支持独特的查询机制,比如数据库可以根据更加合理的策略来提高查询缓存命中率.另一方面,绕过内核缓冲区也可以减少系统内存的开销,因为内核缓冲区本身就在使用系统内存.  
Linux提供了对这种需求的支持,即在open()系统调用中增加参数选项O_DIRECT,用它打开的文件便可以**绕过内核缓冲区的直接访问**,这样便有效避免了CPU和内存的多余时间开销.  

对于使用直接I/O这种优化,不是在任何场景下都能发挥作用.在处理小文件请求时,发送数据的环节在整个过程中所占时间的比例相比于大文件请求时要小很多,所以对于这部分的优化效果不是十分明显.   
####  异步I/O  
 有些时候,同步和异步,阻塞和非阻塞很容易被混淆.其实他们完全不是一回事,而且它们修饰的对象也不同.**阻塞和非阻塞**是指进程访问的数据尚未就绪,进程是否需要等待,简单说这相当于函数内部的实现区别,即未就绪时是直接返回还是等待就绪;而**同步和异步**是指访问数据的机制,**同步**一般指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞,**异步**则是指主动请求数据后便可以继续处理其他任务,随后等待I/O操作完毕的通知,这可以使进程在数据读写时也不发生阻塞.  
## 3.7 服务器并发策略  
  从本质上讲,所有到达服务器的请求都封装在IP包中,位于网卡的接收缓冲区中,这时候Web服务器软件要做的事情就是不断地读取这些请求,然后进行处理,并将结果写到发送缓冲区,这其中包含了一系列的I/O操作和CPU计算,而设计一个并发策略的目的,就是让I/O操作和CPU计算尽量重叠进行,一方面让CPU在I/O等待时不要太空闲,另一方面让CPU在I/O调度上尽量花费最少的时间.  
几种常见的Web服务器并发策略:  
#### 一个进程处理一个连接,非阻塞I/O  
   既然一个进程处理一个连接,那么在并发请求同时到达时,服务器必然要准备多个进程来处理请求.  

早期的一种方式是采用**fork模式**.由主进程负责accept()来自客户端的连接,一旦接受连接,便马上fork()一个新的进程来处理,处理结束后,这个进程便被销毁. fork()的开销成为影响性能的关键.  
 
另一种方式是**prefork模式**.这种方式由主进程预先创建一定数量的子进程,每个请求由一个子进程来处理,但是每个子进程可以处理多个请求.父进程往往只负责管理子进程,根据站点负载来调整子进程的数量,相当于动态维护一个进程池.  

对于accept()的方式,有以下两种策略:  
+ 主进程使用非阻塞accept()来接收连接,当建立连接后,主进程将任务分配给空闲的子进程来处理;  
+ 所有子进程使用阻塞accept()来竞争接收连接,一旦一个子进程建立连接后,它将继续进行处理.  

Apache 2.x便采用第二种策略,在这种accept()阻塞竞争的情况下,虽然从代码上看似只有一个子进程的accept()可以返回.但实际上,按大多数TCP栈的实现方法,当一个请求连接到达时,内核会激活所有阻塞在accept()的子进程,但只有一个能够成功获得连接并返回到用户空间,而其余的子进程由于得不到连接额继续回到休眠状态,这种"抖动"也造成了一定的额外开销.   

Apache这种多进程模型的开销限制了它的并发连接数,但是Apache也有自身的优势,比如从稳定性和兼容性的角度看,多进程模型的优势正体现在它相对安全的独立进程,任何一个子进程的崩溃都不会影响Apache本身,Apache父进程可以创建新的子进程;另一方面,Apache毕竟经过长期的考验和广泛使用,它的功能模块非常丰富,比如各种动态脚本的支持,虚拟主机管理,URL Rewrite,SSL加密,SSL(服务器端静态网页包含),目录浏览和管理等,而且安装和配置都相当简单,有大量的官方文档可以参考.所以,对于一些并发数要求不高(如150以内)的站点,如果同时对其功能有所依赖,那么Apache便是非常不错的选择.  

#### 一个线程处理一个连接,非阻塞I/O  
 这种方式允许在一个进程中通过多个线程来处理多个连接,其中每一个线程处理一个连接.Apache的worker多路处理模块便采用这种方式,它的目的主要在于减少prefork模式中太多进程的开销,是Apache可以支持更多的并发连接.  
 
Apache的**worker模型**可以说是一种多进程和多线程的混合方式,它的MPM配置有些类似于prefork,但是增加了每个进程最大线程数以及最大总线程数的配置,根据配置,Apache主进程 会创建很少的子进程,每个子进程又拥有一定数量的线程.  

在实际测试中,这种方式的表现并不比**prefork**有太大的优势,因为虽然它使用大量线程代替进程,但是这些线程实际上都是有内核进程调度器管理的轻量级进程,它们的上下文切换开销依然存在.  
在实际应用中,worker模型的处境比较尴尬,人们几乎很少使用它,因为它的优点并不明显,一旦人们意识到Apache无法满足需要时,便马上会使用其他的轻量级Web服务器.  
#### 一个进程处理多个连接,非阻塞I/O  
 它存在一个潜在条件:多路I/O就绪通知的应用.
 通常,我们将处理多个连接的进程称为worker进程,或者服务进程.  
 
 在这种模型中,有时候还会涉及独立的listener进程,专门负责接收新的连接,然后分配任务给各个worker,这样做的好处是可以根据各个worker的负载来平衡调度任务,但是任务调度由一定的开销,所以在我们常见的模型中一般是由worker进程来进行接收.另外,对于超时连接的管理,理论上也可以由独立的进程来处理,但是为了减少进程切换,一般也在worker中完成.  

有些时候Web服务器会使用worker线程来代替worker进程,但是这种线程实际上通常都是内核级线程,它们在处理多路I/O的方式上基本相同,所以可以看成是worker进程的一个迷你版.  

大量的worker进程可以维持更多的活跃连接数.但此刻每个连接的下载速度会受到一定的限制.所以如何决定worker进程数完全取决于你的倾向,即你希望为更多的用户提供慢速下载服务,还是希望为有限的用户提供快速的下载服务.  
#### 一个线程处理多个连接,异步I/O  
 即便是拥有高性能的多路I/O就绪通知方法,但是磁盘I/O操作的等待还是无法完全避免,当我们对磁盘文件调用read()或者通过sendfile()直接发送数据时,设置文件描述符为非阻塞没有任何意义,如果要读取的数据不在磁盘缓冲区,磁盘便开始动用物理设备来读取数据,这个时候整个进程的其他工作都必须等待.更加高效的方法便是对磁盘文件操作使用异步I/O,但实际上目前很少有Web服务器支持这种真正意义上的异步I/O.
 
 
