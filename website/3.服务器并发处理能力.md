 我们希望一台服务器在单位时间内能处理的请求越多越好,这也成了Web服务器的能力高低所在,它体现了我们常说的"服务器并发处理能力".本章所说的服务器,主要指用于提供HTTP服务的服务器,但是本章中所涉及的一些关于操作系统和内核的内容,并不限于Web服务器.  
## 3.1 吞吐率  
 我们用**吞吐率**来描述Web服务器的并发处理能力,即单位时间内Web服务器处理的请求数.  
 在一些常见的Web服务器软件中,通常会提供当前服务器运行状况以及吞吐率的查看方法,帮助我们对服务器吞吐率随时进行了解和监控,比如Apache的mod_status模块和Lighttpd的mod_status模块.  
#### 吞吐率和压力测试  
 相对于吞吐率,我们更加关心的是**最大吞吐率**,即单位时间内服务器能够处理的最大请求数.我们普遍采用"压力测试"的方法,通过模拟足够数目的并发用户数,分别持续发送一定的HTTP请求,并统计测试持续的总时间,计算出基于这种"压力"下的吞吐率,即为一个平均计算值.  
 
 另一方面,在Web服务器的实际工作中,其处理的HTTP请求通常包括对很多不同资源的请求,也就是请求不同的URL,比如这些请求有的是获取图片,有的是获取动态内容,显然服务器处理这些请求所花费的时间各不相同,而这些请求的不同时间的组成比例又是不确定的.但是我们在压力测试的时候若想要模拟这种不同请求交错地情况会给我们考察处理器并发能力带来难以想象的困难,我们知道在一个含有较多变量的数据模型中求解最优解是非常困难的,所以
 我们一般都简化模型,对同一个特定的有代表性的请求进行压力测试,然后根据需要,对多个请求的吞吐率按照比例计算加权平均值.  
 
 正是因为这些请求性质的不同,Web服务器并发能力强弱的关键便在于如何针对不同的请求性质来设计**最优并发策略**.  
#### 压力测试的前提条件  
 吞吐率的前提条件包括压力的描述和请求性质的描述,压力的描述包括**并发用户数**和**总请求数**,也就是模拟多少个用户同时向服务器发送多少个请求.请求性质则是对请求的URL所代表的**资源的描述**.  
#### 并发用户数  
 指:在某一时刻同时向服务器发送请求的用户总数.  
 对于压力测试中提到的每一个用户,连续发送请求实际上是指在发送一个请求并接收到响应数据后再发送下一个请求.故从微观层面上来看,
 当一个用户向服务器连续进行1000次请求的过程中,任何时刻服务器的网卡接收缓冲区中只有来自该用户的一个请求,而100个用户同时向服务器分别进行10次请求的过程中,
 服务器网卡接收缓冲区中最多有100个等待处理的请求,显然这时候服务器的压力更大.  
 
 **并发用户数**别名:**并发数**,**并发连接数**.  
 **服务器的最大并发数**,需要在服务器和用户双方期待的最大利益下进行权衡.  
 
 当**实际并发用户数**大于我们通过压力测试得出的服务器所能支持的最大并发数时,必然造成一部分用户需要等待超过预期的时间,影响了站点的服务质量.所以,得出最大并发数的意义,在于了解服务的承载能力,并且结合用户规模考虑适当的扩展方案.  
 在考虑实际用户规模的时候,我们要了解,用户访问Web站点通常使用的浏览器在下载一个网页以及网页中多个组件时,采用多线程的并发下载方式,但是对同一域名下URL的并发下载数是有最大限制的.虽然如此,一个真实的用户可能会给服务器带来两个或更多的并发用户数的压力.在书中为简化模型认为每个用户的并发下载数为1.  
 从Web服务器的角度来看,实际并发用户数也可以理解为Web服务器当前维护的代表不同用户的文件描述符总数,也就是**并发连接数**.  
 
 当实际并发用户数稍稍大于服务器所能维护的文件描述符上限时.如果请求的性质决定了处理每个请求花费的时间非常少,我们希望服务的最大并发数可以大于最大并发连接数.如果请求的性质决定了处理每个请求要花费相当长的时间,我们希望服务的最大并发用户数小于理论上的最大并发连接数.  
 
 **总结**:从某种意义上来说,Web服务器所做的工作的本质就是,争取以最快的速度将内核缓冲区中的用户请求数据一个不剩地都拿回来,然后进最大努力同时快速处理完这些请求,并将响应数据放到啮合维护的另一块用于发送数据的缓冲区中,接下来再尽快处理下一拨请求,并尽量让用户请求在内核缓冲区中不要等太久.  
#### 请求等待时间  
 **用户平均请求等待时间**主要用于衡量服务器在一定并发用户数的情况下,对于单个用户的服务质量;而**服务器平均请求处理时间**用于衡量服务器的整体服务质量,它其实就是吞吐率的倒数.  
#### 硬件环境  
 在以上压力测试中,我们普遍使用的Web服务器基本硬件配置如下:  
 CPU:Intel(R) Xeon(R) CPU 1.60GHz  
 内存:4GB  
 硬盘转速:15k/min  
#### 压力测试  
 有了这些前提,我们就可以用压力测试软件来计算吞吐率了,本书中大部分压力测试使用Apache附带的ab,它非常容易使用,完全可以模拟以上各种前提条件.另外,ab可以直接在Web服务器本地发起测试请求,这至关重要,因为我们希望测试的是服务器的处理时间,而不包括数据的网络传输时间以及用户PC本地的计算时间.  
 ab进行一切测试的本质都是基于HTTP,所以可以说它是对于Web服务器软件的黑盒性能测试,它获得的一切数据和计算结果,都可以通过HTTP来解释.  
 
 另有一些压力测试软件,包括LoadRunner,Jmeter等,则是不同程度上包含了服务器处理之外的时间,比如LoadRunner运行在用户PC上,可以录制浏览器的行为,这种测试的结果往往侧重于站在用户的角度.  
 
 我们对Web服务器的几个常见性能指标做了详细介绍,影响这些指标的因素,除去服务器的硬件配置,就是前面提到的**并发策略**.简单地说,并发策略的设计就是在服务器同时处理较多请求的时候,如何合理协调并充分利用CPU计算和I/O操作,使其在较大并发用户数的情况下提供较高的吞吐率.  
 并不存在一个对所有性质的请求都高效的并发策略,我们只能也只有了解并根据这些性质来选择最佳的并发策略,高性能Web站点才会离你更近一步.  
 
## 3.2 CPU并发计算  
 服务器之所以可以同时处理多个请求,在于操作系统通过**多执行流体系设计**使得多个任务可以轮流使用系统资源,这些资源包括**CPU,内存以及I/O**等.  
#### 进程  
 多执行流的一班实现便是进程.从本质上讲,多进程的好处并不仅仅在于CPU时间的轮流使用,还在于对CPU计算和I/O操作进行了很好的重叠作用,这里的I/O主要是指磁盘I/O和网络I/O,它们的速度比CPU慢得多.事实上,大多数进程的时间都主要消耗在了I/O操作上.  
 进程的调度由内核来进行,从内核的观点看,进程的目的就是担当分配系统资源的实体.同时,进程也可以理解为记录程序实例当前运行到什么程度地一组数据,多个进程通过不同的进程描述符与这些数据进行关联.  
 每个进程都有自己独立的内存地址空间和生命周期.当子进程被父进程创建后,便将父进程地址空间的所有数据复制到自己的地址空间,完全继承父进程的所有上下文信息,它们之间可以通信,但是不互相依赖,也无权干涉彼此的地址空间.  
 进程的创建使用fork()系统调用,它的开销虽然不是很昂贵,但是在繁忙的服务器上频繁地创建进程,其开销可能成为影响性能的主要因素.  
#### 轻量级进程  
 轻量级进程由一个新的系统调用clone()来创建,并由内核直接管理, 像普通进程一样独立存在,各自拥有进程的描述,但是这些进程已经允许共享一些资源,比如地址空间,打开的文件等.轻量级进程减少了内存的开销,并为多进程应用程序的数据共享提供了直接支持,但是其上下文切换的开销还是在所难免的.  
#### 线程  
 POSIX线程的两种实现方式:  

1. 定义了线程的接口"phread",有很多种具体实现,有些不是由内核来直接支持,在这种情况下,从内核的角度看,多线程知识一个普通的进程,它是由用户态通过一些库函数模拟实现的多执行流,所以多线程的管理完全在**用户态**完成,这种实现方式下线程切换的开销相比于进程和轻量级进程都要少些,但是她在处理器的服务器(SMP)中表现较差,因为**只有内核的进程调度器才有权利分配多个CPU的时间**.  
2. LinuxThreads,它可以说是内核级的线程库,因为它通过clone()来创建线程,也就是说它的实现原理是将线程和轻量级进程一对一关联,每个线程实际上就是一个轻量级进程,这使得线程完全由内核的进程调度器来管理,所以他对于SMP的支持良好,但线程切换的开销相比于用户态线程要多一些.  

#### 进程调度器  
 内核中的进程调度器维护着各种状态(挂起,就绪或其他等)的进程队列.进程调度器的一项重要工作就是决定下一个运行的进程,如果运行队列中不止有一个进程,每个进程要高速进程调度器它们的紧急程度,即进程优先级.进程优先级除了可以由进程自己决定,进程调度器在进程运行时也可以动态调整它们的优先级,目的是为了让所有进程更好地重叠利用系统资源.  
#### 系统负载  
 在进程调度器维护的运行队列中,任何时刻至少存在一个进程,那就是正在运行的进程.而当运行队列中不止有一个进程时,就说明此时CPU比较抢手,其他进程还在等着呢,进程调度器应该尽快让正在运行的进程释放CPU.  
 **系统负载越高,代表CPU越繁忙,越无法很好地满足所有进程的需要**  
 定义:系统负载是指单位时间内运行队列中就绪等待的进程数平均值.所以当运行队列中就绪进程不需要等待就可以马上获得CPU时,系统负载非常低,系统.  响应非常快.  
#### 进程切换  
 为了让所有的进程可以轮流使用系统资源,进程调度器在必要的时候挂起正在运行的进程,同时恢复以前挂起的某个进程,这种行为称为**进程切换**,也就是**上下文切换**,上下文表示进程运行到何种程度.  
 进程拥有自己独立的内存空间,但是每个进程都只能共享CPU寄存器.一个进程被挂起的本质就是将它在CPU寄存器中的数据拿出来暂存在内核态堆栈中,而一个进程恢复工作的本质就是将它的数据重新装入CPU寄存器,这段装入和移出的数据我们称为"硬件上下文",它也是进程上下文的一部分,初次之外,进程上下文中还包含了进程运行时需要的一切状态信息.  
 
 如果我们希望服务器支持较大的并发数,那么就要尽量减少上下文切换次数,最简单的做法就是减少进程数,尽量使用线程配合其他I/O模型来设计并发策略.  
#### IOWait  
 在CPU的使用率报告中,除了用户控件和内核空间的CPU使用率以外,通常我们HIA关注IOWait,它是指CPU空闲并且等待I/O操作完成的时间比例.它的设计触发点是用来衡量CPU的性能.当IOWait很高的时候,说明当前任务的CPU时间开销相对于I/O操作时间来说比较少,通常对于依赖磁盘I/O的应用来说,这比较正常,因为CPU的速度比磁盘I/O越来越快,特别是在随机的磁盘I/O操作中,大量的寻址时间是无法避免的.  
 IOWait有时也有可能会误导我们,我们需要判断到底是实际的磁盘I/O提高了还是其实只是CPU使用率提高了.总之它是一个耐人寻味的指标,你需要根据站点的实际情况来做出合理的判断.  
#### 锁竞争  
 在服务器处理大量并发请求的时候,多个请求处理任务之间存在一些资源抢占竞争.这就需要有一种机制来维持秩序,比如多个线程同时写一个日志文件,为了防止写入的数据发生位置错乱,就需要我们自己来控制先后顺序,也就是要保证线程安全.我们一般用**锁**机制来控制资源的占有,当一个任务占有资源的时候,我们锁住资源,这时候其他任务都在等待锁的释放,这种现象我们称为锁竞争.  
## 3.3 系统调用  
 前面的内容中提到进程的**用户态**和**内核态**两种运行模式,这是Linux为进程设计的两种运行级别,进程可以在两种模式之间切换,这也需要一定的开销.进程通常运行在用户态,这时候可以使用CPU和内存来完成一些任务(如进程数学计算),而当进程需要对硬件外设进行操作的时候(如读取磁盘文件,发送网络数据等),就必须切换到内核态,这时候它将拥有更多的权利来操控整个计算机,当在内核态的任务完成后,进程又切换回用户态.  
 进程切换到内核态的一系列过程,对使用高级语言的开发者来说是透明的,程序代码只在需要的时候进行系统调用即可.内核提供了一系列的系统调用,同时,C库函数将系统调用封装在编程接口,提供给用户态的进程.用户态的进程可以直接进行系统调用,也可以使用封装了系统调用的C API,比如write()系统调用,它的封装API之一就是用于发送网络数据的send().  
 
 这种**用户态和内核态的分离**,动机主要在于提高系统底层安全性以及简化开发模型.由于所有进程都必须通过内核提供的系统调用来操作硬件,所以不必担心应用程序对硬件进行非法操作,由于将底层的实现都屏蔽在了系统调用中,也大大简化了用户态应用开发的难度.由于系统调用设计进程胸用户态到内核态的切换,导致一定的内存空间交换,这也是一定程度上的上下文切换,所以系统调用的开销通常认为是比较昂贵的.**减少不必要的系统调用**,这也是Web服务器性能优化的一个方面.  
 系统调用的减少对于降低请求处理时间(吞吐率增加)有着不可忽略的作用.  
## 3.4 内存分配  
 在Web服务器的工作过程中,需要用到大量的内存,这使得内存的分配和释放工作显得尤为重要.Web服务器处理成千上万的HTTP请求,内存堆栈的分配和复制次数变得更加频繁.我们可以通过改善数据结构和算法复杂度来适当减少数据复制时间,而对于内存的分配,很多Web服务器使用了各自的策略来提高效率.  
 **Apache(多进程模型)**在运行时的内存使用量很大.它使用了基于内存池策略的内存管理方案,并将它抽象出来后移入ARP库中作为通用内存管理模块.这种方案使得Apache在运行开始时便一次性申请大片的内存作为内存池,这样在随后需要的时候只要在内存池中直接获取,而不需要再次分配,我们知道频繁的内存分配和释放会引发一定时间的内存整理,这本身便影响了性能.另一方面,内存池的使用使得Apache的内存管理更加安全,因为即便是某处内存使用后忘记释放也没关系,内存池在Apache关闭时会彻底释放.即便使用了内存池,由于机制问题,Apache仍然就像拖着沉重身体的傻大个,内存池对于性能的弥补微不足道.  
 **Lighttpd(单进程模型)**内存使用量小很多.  
 **Nginx(单进程模型)**内存使用量更小.  
 
 内存分配策略的设计是Web服务器并发处理能力的重要保障.  
## 3.5 持久连接  
 **持久连接**(长连接),它本身是TCP通信的一种普通方式,即在一次TCP连接中持续发送多份数据而不断开连接;  
 与之相反的是**短连接**,也就是建立连接后发送一份数据便断开,然后再次建立连接发送下一份数据.  
一般而言,是否采用持久连接完全取决于应用的特点和需要.从性能的角度看,建立TCP连接的操作本身便是一项不小的开销,所以在允许的情况下,连接次数越少,越有利于性能的提升.  

 在Web应用**通信层**中,由于HTTP的无状态特性,使得HTTP通信毫不依赖于TCP长连接,长久以来大家习惯了"一次性"的HTTP通信,即一次TCP连接处理一个HTTP请求.然而回归**传输层**,长连接的好处显而易见,它对于密集型的图片或网页等小数据的请求处理有着明显的加速作用.  
 
 HTTP长连接的实施需要浏览器和Web服务器的共同协作,缺一不可.一方面,浏览器需要保持一个TCP连接并重复利用,不断地发送多个请求,另一方面,服务器不能过早地主动关闭连接.要实现这一点并不难,目前的浏览器普遍支持长连接,表现在其发出的HTTP请求数据头中包含关于长连接的声明:Connection:Keep-Alive  这种声明的含义在于高速服务器"如果可以的话,请让我重复这个连接"也就是告诉服务器不要在处理完当前请求后就马上关闭连接.同时,在Web服务器上也要打开长连接的支持,幸运的是,目前所有主流的Web服务器软件都支持长连接,比如在Apache2.2.11中,长连接的支持默认为开启状态,当然你也可以通过以下方式关闭:KeepAlive Off   
 对于长连接的使用关键在于什么时候关闭它.长连接的设置同时出现在浏览器和Web服务器上,因为双发都可以主动关闭.对于IE7,默认的超时时间为1分钟,你也可以通过修改注册表来修改超时时间.对于Web服务器,一般会提供超时时间的配置参数,比如在Apache中,可以通过httpd.conf中的如下参数进行配置:KeepAliveTimeout 30 以上命令设置超时时间为30秒,而在默认情况下,Apache将其设置为5秒.值得注意的是,浏览器和Web服务器各自的超时时间设置不一定一致,所以在实际运行中,是以最短的超时时间为准.  
 
 经过测试,我们得出一些结论:合理地使用长连接会使得吞吐率增高;系统调用数减少(如socket的accept()和close()).  
 有时长连接超时时间过长,对Web服务器的性能也会产生不利的影响.  
 对于Apache这样的多进程模型来讲,如果长连接超时时间过长,比如60秒,那么即便是浏览器没有任何请求,而Apache仍然维持着连接该浏览器的子进程,一旦并发用户数较多,那么Apache将维持着大量的空闲进程,严重影响了服务器性能.  
 对于使用多线程的轻量级Web服务器(如:Nginx),长连接的超时时间过长,导致资源无法占有而引发的损失已经超过了由于重复连接所造成的损失,这的确得不偿失.  
 **持久连接的动机**:尽量减少连接次数,尽量重用连接通道.  
## 3.6 I/O模型  
 数据生命的意义在于输入/输出,计算机的重要工作之一便是负责各种设备的数据输入/输出,也就是I/O操作.  
 I/O操作根据设备的不同分为很多种类型,比如**内存I/O(快),网络I/O(慢),磁盘I/O**(慢).  
 本章我们主要关注**网络数据的接收和发送**,**磁盘的访问**.我们将其归纳为多种模型,称为I/O模型,它们的本质区别便在于CPU的参与方式.  
#### PIO与DMA  
 说说慢速I/O设备和内存之间的数据传输方式.  
 
 1. 很早以前的**PIO**:磁盘和内存之间的数据传输需要CPU控制,即我们读取磁盘文件到内存中,数据要经过CPU存储转发.显然这种方式非常不合理,需要占用大量的CPU时间来读取文件,造成文件访问时系统几乎停止响应.  
 2. **DMA(直接内存访问)**取代了PIO:不经过CPU而直接进行磁盘和内存的数据交换.在DMA模式下,CPU值需要向DMA控制器下达指令,让DMA控制器来处理数据的传送即可,DMA控制器通过系统总线来传输数据,传送完毕再通知CPU,这样就在很大程度上降低了CPU占有率,大大节省了系统资源,而它的传输速度与PIO的差异其实并不是十分明显,因为这主要取决于慢速设备的速度.  
 
#### 同步阻塞I/O  
 当进程调用某些涉及I/O操作的系统盗用后库函数时,比如:accept(),send(),recv()等,进程便暂停下来,等待I/O操作完成后再继续进行.这是一种简单而有效地I/O模型,它可以和多进程合起来有效地利用CPU资源,但是其代价就是多进程的大量内存开销.  
#### 同步非阻塞I/O  
 在同步阻塞I/O中,进程实际上等待时间可能包括两部分,一个是等**待数据的就绪**,另一个是**等待数据的复制**,对于网络来说,前者时间可能更长一点.与此不同的是,同步非阻塞I/O的调用不会等待数据的就绪,如果数据不可读或者不可写,它会立即告诉进程.比如我们使用非阻塞recv()接收网络数据的时候,如果网卡缓冲区中没有课接收的数据,函数就及时返回,告诉没有进程数据可读了.相比于阻塞I/O,这种非阻塞I/O结合反复轮询来尝试数据是否就绪,防止进程被阻塞,最大的好处便在于可以在一个进程里同时处理多个I/O操作.但正是由于需要进程执行多次的轮询来查看数据是否就绪,这花费了大量的CPU时间,使得进程处于忙碌等待状态.  
 
 **非阻塞I/O一般只针对网络I/O有效**,我们只要在socket的选项设置中使用O_NONBLOCK即可,这样对于该socket的send()或revc()便采用非阻塞方式.值得注意的是,对于磁盘I/O,非阻塞I/O并不产生效果.  *
#### 多路I/O就绪通知  
 
 
 
